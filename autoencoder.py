from torch import nn

"""
Autoencoder

This model is currently used to reduce the dimensionality of the image vectors produced by the ResNet50 model.
Thhis model has, in practice, proven itself to be more effective in our image inference tasks
than various ViT models (primarily google/vit-base-patch16-224).

However, vectors stored within the PGVector database are limited to 2000 dimensions.
Therefore, this model has been trained on our parsed image dataset to reduce the
dimensionality of the vectors generated by the ResNet50 model from 2048 to 2000.
"""

VECTORIZER_OUTPUT_DIM = 2048
TARGET_VECTOR_DIM = 2000


class Autoencoder(nn.Module):
    def __init__(self, input_dim=VECTORIZER_OUTPUT_DIM, encoding_dim=TARGET_VECTOR_DIM):
        super(Autoencoder, self).__init__()

        """
        Encoder
        VECTORIZER_OUTPUT_DIM -> TARGET_VECTOR_DIM
        The dimensionality reduction for this use case is so minor that good
        results can be achieved with a single pair of linear and activation layers.
        """
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, encoding_dim),
            nn.ReLU(True),
        )

        """
        Decoder
        TARGET_VECTOR_DIM -> VECTORIZER_OUTPUT_DIM
        """
        self.decoder = nn.Sequential(
            nn.Linear(encoding_dim, input_dim),
            nn.ReLU(True),
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

    def encode(self, x):
        return self.encoder(x)
